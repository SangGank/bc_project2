{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. pandas 및 pickle 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn.metrics\n",
    "import pickle as pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_to_label pickle 에서 불러오려면 아래 셀 uncomment 후 경로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_to_label dict 직접 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_label = {0: 'no_relation', 1: 'org:top_members/employees', 2: 'org:members', 3: 'org:product', 4: 'per:title', 5: 'org:alternate_names', 6: 'per:employee_of', 7: 'org:place_of_headquarters', 8: 'per:product', 9: 'org:number_of_employees/members', 10: 'per:children', 11: 'per:place_of_residence', 12: 'per:alternate_names', 13: 'per:other_family', 14: 'per:colleagues', 15: 'per:origin', 16: 'per:siblings', 17: 'per:spouse', 18: 'org:founded', 19: 'org:political/religious_affiliation', 20: 'org:member_of', 21: 'per:parents', 22: 'org:dissolved', 23: 'per:schools_attended', 24: 'per:date_of_death', 25: 'per:date_of_birth', 26: 'per:place_of_birth', 27: 'per:place_of_death', 28: 'org:founded_by', 29: 'per:religion'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klue_re_micro_f1(preds, labels):\n",
    "    \"\"\"KLUE-RE micro f1 (except no_relation)\"\"\"\n",
    "    label_list = ['no_relation', 'org:top_members/employees', 'org:members',\n",
    "       'org:product', 'per:title', 'org:alternate_names',\n",
    "       'per:employee_of', 'org:place_of_headquarters', 'per:product',\n",
    "       'org:number_of_employees/members', 'per:children',\n",
    "       'per:place_of_residence', 'per:alternate_names',\n",
    "       'per:other_family', 'per:colleagues', 'per:origin', 'per:siblings',\n",
    "       'per:spouse', 'org:founded', 'org:political/religious_affiliation',\n",
    "       'org:member_of', 'per:parents', 'org:dissolved',\n",
    "       'per:schools_attended', 'per:date_of_death', 'per:date_of_birth',\n",
    "       'per:place_of_birth', 'per:place_of_death', 'org:founded_by',\n",
    "       'per:religion']\n",
    "    no_relation_label_idx = label_list.index(\"no_relation\")\n",
    "    preds = label_to_num(preds.values)\n",
    "    labels = label_to_num(labels.values)\n",
    "\n",
    "    label_indices = list(range(len(label_list)))\n",
    "    label_indices.remove(no_relation_label_idx)\n",
    "    return sklearn.metrics.f1_score(labels, preds, average=\"micro\", labels=label_indices) * 100.0\n",
    "\n",
    "\n",
    "def label_to_num(label):\n",
    "  num_label = []\n",
    "  with open('../code/dict_label_to_num.pkl', 'rb') as f:\n",
    "    dict_label_to_num = pickle.load(f)\n",
    "  for v in label:\n",
    "    num_label.append(dict_label_to_num[v])\n",
    "  \n",
    "  return num_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixmaster(df1, df2, weight1, weight2):\n",
    "    result = []\n",
    "    df1= np.array(list(map(float, df1[1:-1].split(', ')))) * weight1\n",
    "    df2= np.array(list(map(float, df2[1:-1].split(', ')))) * weight2\n",
    "    result =np.mean([df1, df2], axis=0)\n",
    "    result = result/result.sum()\n",
    "    result = '[' + ', '.join(map(str, result)) + ']'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_label(x):\n",
    "    x= np.array(list(map(float, x[1:-1].split(', '))))\n",
    "    return num_to_label[np.argmax(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(folder_name, file_name1, file_name2, weight1 = 1, weight2 = 1):\n",
    "    ens1 = pd.read_csv(f'{folder_name}/{file_name1}')\n",
    "    ens2 = pd.read_csv(f'{folder_name}/{file_name2}')\n",
    "    result = ens1.copy()\n",
    "    \n",
    "    result.probs=result.id.apply(lambda x: mixmaster(ens1.probs.iloc[x],ens2.probs.iloc[x],weight1,weight2))\n",
    "    \n",
    "    result.pred_label= result.probs.apply(lambda x: change_label(x))\n",
    "    \n",
    "    return result\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "0 1\n",
      "0 2\n",
      "0 3\n",
      "1 2\n",
      "1 3\n",
      "2 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'21_roberta-large_19_roberta-large_lr': 75.45310015898251,\n",
       " '19_roberta-large_lr_sub_57': 75.33206831119543,\n",
       " '21_roberta-large_sub_57': 75.13394264103371,\n",
       " '14_roberta-large_19_roberta-large_lr': 75.06014434643144,\n",
       " '14_roberta-large_21_roberta-large': 74.86408698433003,\n",
       " '14_roberta-large_sub_57': 74.78455154803702}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.isdir('./ensemble_result')==False:\n",
    "    os.mkdir('./ensemble_result')\n",
    "folder_name = './ensemble'\n",
    "file_list = os.listdir(folder_name)\n",
    "count_file = len(file_list)\n",
    "\n",
    "correct = pd.read_csv('../data/dataset/test/dev_final.csv')\n",
    "\n",
    "f1_scores={}\n",
    "print(count_file)\n",
    "for file_1 in range(count_file):\n",
    "    for file_2 in range(file_1+1,count_file):\n",
    "        \n",
    "        print(file_1 , file_2)\n",
    "        file_name = f'{file_list[file_1][6:-4]}_{file_list[file_2][6:-4]}'\n",
    "        ens_result = ensemble(folder_name,file_list[file_1],file_list[file_2])\n",
    "        ens_result.to_csv(f'./ensemble_result/train_{file_name}.csv')\n",
    "        ens_result= pd.concat([ens_result,correct],axis=1)\n",
    "        f1_scores[file_name]=klue_re_micro_f1(ens_result.pred_label,ens_result.label)\n",
    "\n",
    "f1_scores=dict(sorted(f1_scores.items(), key=lambda x:-x[1]))     \n",
    "f1_scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'21_roberta-large_5_19_roberta-large_lr_5': 75.45310015898251,\n",
       " '21_roberta-large_5_19_roberta-large_lr_4': 75.44891148895597,\n",
       " '21_roberta-large_4_19_roberta-large_lr_5': 75.34573199809252,\n",
       " '21_roberta-large_5_19_roberta-large_lr_3': 75.22208121827411,\n",
       " '21_roberta-large_3_19_roberta-large_lr_5': 75.00396762418664,\n",
       " '21_roberta-large_5_19_roberta-large_lr_2': 74.97233201581027,\n",
       " '21_roberta-large_2_19_roberta-large_lr_5': 74.94850261448265,\n",
       " '21_roberta-large_5_19_roberta-large_lr_1': 74.689318861098,\n",
       " '21_roberta-large_1_19_roberta-large_lr_5': 74.65145754119138}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_name = './ensemble'\n",
    "file_list = os.listdir(folder_name)\n",
    "count_file = len(file_list)\n",
    "if os.path.isdir('./ensemble_result')==False:\n",
    "    os.mkdir('./ensemble_result')\n",
    "\n",
    "correct = pd.read_csv('../data/dataset/test/dev_final.csv')\n",
    "f1_scores={}\n",
    "file_name1= 'train_21_roberta-large.csv'\n",
    "file_name2 = 'train_19_roberta-large_lr.csv'\n",
    "\n",
    "for weight1 in range(1,6):\n",
    "\n",
    "    print(weight1)\n",
    "\n",
    "    file_name = f'{file_name1[6:-4]}_{weight1}_{file_name2[6:-4]}_5'\n",
    "    ens_result = ensemble(folder_name,file_name1,file_name2,weight1,5)\n",
    "    ens_result.to_csv(f'./ensemble_result/{file_name}.csv')\n",
    "    ens_result= pd.concat([ens_result,correct],axis=1)\n",
    "    f1_scores[file_name]=klue_re_micro_f1(ens_result.pred_label,ens_result.label)\n",
    "\n",
    "for weight2 in range(1,6):\n",
    "\n",
    "    print(weight2)\n",
    "\n",
    "    file_name = f'{file_name1[6:-4]}_5_{file_name2[6:-4]}_{weight2}'\n",
    "    ens_result = ensemble(folder_name,file_name1,file_name2,5,weight2)\n",
    "    ens_result.to_csv(f'./ensemble_result/train_{file_name}.csv')\n",
    "    ens_result= pd.concat([ens_result,correct],axis=1)\n",
    "    f1_scores[file_name]=klue_re_micro_f1(ens_result.pred_label,ens_result.label)\n",
    "\n",
    "f1_scores=dict(sorted(f1_scores.items(), key=lambda x:-x[1]))\n",
    "f1_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['no_relation', 'org:top_members/employees', 'org:members', 'org:product', 'per:title', 'org:alternate_names', 'per:employee_of', 'org:place_of_headquarters', 'per:product', 'org:number_of_employees/members', 'per:children', 'per:place_of_residence', 'per:alternate_names', 'per:other_family', 'per:colleagues', 'per:origin', 'per:siblings', 'per:spouse', 'org:founded', 'org:political/religious_affiliation', 'org:member_of', 'per:parents', 'org:dissolved', 'per:schools_attended', 'per:date_of_death', 'per:date_of_birth', 'per:place_of_birth', 'per:place_of_death', 'org:founded_by', 'per:religion'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_to_label.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores=dict(sorted(f1_scores.items(), key=lambda x:-x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name ='train_'+'19_roberta-large8379_checkpoint-6000_5_sub_57_4_5_19_roberta-large_lr_checkpoint-8000_21_roberta-large1_5_checkpoint-6000_1'+'.csv'\n",
    "x= pd.read_csv(f'./ensemble_result/{file_name}')\n",
    "x.to_csv(f'./save_best/{file_name}')\n",
    "x.to_csv(f'./ensemble/{file_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train_15_roberta-large_3.8_sub_42_5.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './ensemble/train_15_roberta-large_3.8_sub_42_5.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-63e2519d4d3c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_1\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mfile_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'{file_list[file_1][6:-4]}_{file_2[6:-4]}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mens_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfile_2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mens_result\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'./ensemble_result/train_{file_name}.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mens_result\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mens_result\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-41bb11ca3b78>\u001b[0m in \u001b[0;36mensemble\u001b[0;34m(folder_name, file_name1, file_name2, weight1, weight2)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mens1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{folder_name}/{file_name1}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mens2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'{folder_name}/{file_name2}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mens1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './ensemble/train_15_roberta-large_3.8_sub_42_5.csv'"
     ]
    }
   ],
   "source": [
    "if os.path.isdir('./ensemble_result')==False:\n",
    "    os.mkdir('./ensemble_result')\n",
    "folder_name = './save_'\n",
    "file_list = os.listdir(folder_name)\n",
    "count_file = len(file_list)\n",
    "\n",
    "correct = pd.read_csv('../data/dataset/test/dev_final.csv')\n",
    "\n",
    "f1_scores={}\n",
    "file_2 = 'train_15_roberta-large_3.8_sub_42_5.csv'\n",
    "\n",
    "for file_1 in range(count_file):\n",
    "    print(file_1 , file_2)\n",
    "    file_name = f'{file_list[file_1][6:-4]}_{file_2[6:-4]}'\n",
    "    ens_result = ensemble(folder_name,file_list[file_1],file_2)\n",
    "    ens_result.to_csv(f'./ensemble_result/train_{file_name}.csv')\n",
    "    ens_result= pd.concat([ens_result,correct],axis=1)\n",
    "    f1_scores[file_name]=klue_re_micro_f1(ens_result.pred_label,ens_result.label)\n",
    "\n",
    "f1_scores=dict(sorted(f1_scores.items(), key=lambda x:-x[1]))     \n",
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2\n",
      "3.4\n",
      "3.6\n",
      "3.8\n",
      "4.0\n",
      "4.2\n",
      "4.4\n",
      "4.6\n",
      "4.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'15_roberta-large_3.8_sub_42_5': 71.50374740870674,\n",
       " '15_roberta-large_4.0_sub_42_5': 71.49465624501515,\n",
       " '15_roberta-large_3.2_sub_42_5': 71.488,\n",
       " '15_roberta-large_3.4_sub_42_5': 71.46282973621103,\n",
       " '15_roberta-large_3.6_sub_42_5': 71.44911327688129,\n",
       " '15_roberta-large_4.2_sub_42_5': 71.30573248407643,\n",
       " '15_roberta-large_4.8_sub_42_5': 71.19074044712225,\n",
       " '15_roberta-large_4.4_sub_42_5': 71.18105229693211,\n",
       " '15_roberta-large_4.6_sub_42_5': 71.163307411522}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_name = './ensemble'\n",
    "file_list = os.listdir(folder_name)\n",
    "count_file = len(file_list)\n",
    "if os.path.isdir('./ensemble_result')==False:\n",
    "    os.mkdir('./ensemble_result')\n",
    "\n",
    "correct = pd.read_csv('../data/dataset/test/dev_final.csv')\n",
    "\n",
    "f1_scores={}\n",
    "file_name1= 'train_15_roberta-large.csv'\n",
    "file_name2 = 'train_sub_42.csv'\n",
    "\n",
    "for weight in range(1,10):\n",
    "    weight1 = 3+ weight*0.2\n",
    "    print(weight1)\n",
    "\n",
    "    file_name = f'{file_name1[6:-4]}_{weight1}_{file_name2[6:-4]}_5'\n",
    "    ens_result = ensemble(folder_name,file_name1,file_name2,weight1,5)\n",
    "    ens_result.to_csv(f'./ensemble_result/{file_name}.csv')\n",
    "    ens_result= pd.concat([ens_result,correct],axis=1)\n",
    "    f1_scores[file_name]=klue_re_micro_f1(ens_result.pred_label,ens_result.label)\n",
    "\n",
    "# for weight2 in range(1,6):\n",
    "\n",
    "#     print(weight2)\n",
    "\n",
    "#     file_name = f'{file_name1[6:-4]}_5_{file_name2[6:-4]}_{weight2}'\n",
    "#     ens_result = ensemble(folder_name,file_name1,file_name2,5,weight2)\n",
    "#     ens_result.to_csv(f'./ensemble_result/train_{file_name}.csv')\n",
    "#     ens_result= pd.concat([ens_result,correct],axis=1)\n",
    "#     f1_scores[file_name]=klue_re_micro_f1(ens_result.pred_label,ens_result.label)\n",
    "\n",
    "f1_scores=dict(sorted(f1_scores.items(), key=lambda x:-x[1]))\n",
    "f1_scores\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
