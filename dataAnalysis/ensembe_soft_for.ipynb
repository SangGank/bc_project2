{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. pandas 및 pickle 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn.metrics\n",
    "import pickle as pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_to_label pickle 에서 불러오려면 아래 셀 uncomment 후 경로 지정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "num_to_label dict 직접 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_label = {0: 'no_relation', 1: 'org:top_members/employees', 2: 'org:members', 3: 'org:product', 4: 'per:title', 5: 'org:alternate_names', 6: 'per:employee_of', 7: 'org:place_of_headquarters', 8: 'per:product', 9: 'org:number_of_employees/members', 10: 'per:children', 11: 'per:place_of_residence', 12: 'per:alternate_names', 13: 'per:other_family', 14: 'per:colleagues', 15: 'per:origin', 16: 'per:siblings', 17: 'per:spouse', 18: 'org:founded', 19: 'org:political/religious_affiliation', 20: 'org:member_of', 21: 'per:parents', 22: 'org:dissolved', 23: 'per:schools_attended', 24: 'per:date_of_death', 25: 'per:date_of_birth', 26: 'per:place_of_birth', 27: 'per:place_of_death', 28: 'org:founded_by', 29: 'per:religion'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def klue_re_micro_f1(preds, labels):\n",
    "    \"\"\"KLUE-RE micro f1 (except no_relation)\"\"\"\n",
    "    label_list = ['no_relation', 'org:top_members/employees', 'org:members',\n",
    "       'org:product', 'per:title', 'org:alternate_names',\n",
    "       'per:employee_of', 'org:place_of_headquarters', 'per:product',\n",
    "       'org:number_of_employees/members', 'per:children',\n",
    "       'per:place_of_residence', 'per:alternate_names',\n",
    "       'per:other_family', 'per:colleagues', 'per:origin', 'per:siblings',\n",
    "       'per:spouse', 'org:founded', 'org:political/religious_affiliation',\n",
    "       'org:member_of', 'per:parents', 'org:dissolved',\n",
    "       'per:schools_attended', 'per:date_of_death', 'per:date_of_birth',\n",
    "       'per:place_of_birth', 'per:place_of_death', 'org:founded_by',\n",
    "       'per:religion']\n",
    "    no_relation_label_idx = label_list.index(\"no_relation\")\n",
    "    preds = label_to_num(preds.values)\n",
    "    labels = label_to_num(labels.values)\n",
    "\n",
    "    label_indices = list(range(len(label_list)))\n",
    "    label_indices.remove(no_relation_label_idx)\n",
    "    return sklearn.metrics.f1_score(labels, preds, average=\"micro\", labels=label_indices) * 100.0\n",
    "\n",
    "\n",
    "def label_to_num(label):\n",
    "  num_label = []\n",
    "  with open('../code/dict_label_to_num.pkl', 'rb') as f:\n",
    "    dict_label_to_num = pickle.load(f)\n",
    "  for v in label:\n",
    "    num_label.append(dict_label_to_num[v])\n",
    "  \n",
    "  return num_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixmaster(df1, df2, weight1, weight2):\n",
    "    result = []\n",
    "    df1= np.array(list(map(float, df1[1:-1].split(', ')))) * weight1\n",
    "    df2= np.array(list(map(float, df2[1:-1].split(', ')))) * weight2\n",
    "    result =np.mean([df1, df2], axis=0)\n",
    "    result = result/result.sum()\n",
    "    result = '[' + ', '.join(map(str, result)) + ']'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_label(x):\n",
    "    x= np.array(list(map(float, x[1:-1].split(', '))))\n",
    "    return num_to_label[np.argmax(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble(folder_name, file_name1, file_name2, weight1 = 1, weight2 = 1):\n",
    "    ens1 = pd.read_csv(f'{folder_name}/{file_name1}')\n",
    "    ens2 = pd.read_csv(f'{folder_name}/{file_name2}')\n",
    "    result = ens1.copy()\n",
    "    \n",
    "    result.probs=result.id.apply(lambda x: mixmaster(ens1.probs.iloc[x],ens2.probs.iloc[x],weight1,weight2))\n",
    "    \n",
    "    result.pred_label= result.probs.apply(lambda x: change_label(x))\n",
    "    \n",
    "    return result\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'19_roberta-large_lr_sub_57': 75.33206831119543}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.isdir('./ensemble_result')==False:\n",
    "    os.mkdir('./ensemble_result')\n",
    "folder_name = './ensemble'\n",
    "file_list = os.listdir(folder_name)\n",
    "count_file = len(file_list)\n",
    "\n",
    "correct = pd.read_csv('../data/dataset/test/dev_final.csv')\n",
    "\n",
    "f1_scores={}\n",
    "print(count_file)\n",
    "for file_1 in range(count_file):\n",
    "    for file_2 in range(file_1+1,count_file):\n",
    "        \n",
    "        print(file_1 , file_2)\n",
    "        file_name = f'{file_list[file_1][6:-4]}_{file_list[file_2][6:-4]}'\n",
    "        ens_result = ensemble(folder_name,file_list[file_1],file_list[file_2])\n",
    "        ens_result.to_csv(f'./ensemble_result/train_{file_name}.csv')\n",
    "        ens_result= pd.concat([ens_result,correct],axis=1)\n",
    "        f1_scores[file_name]=klue_re_micro_f1(ens_result.pred_label,ens_result.label)\n",
    "\n",
    "f1_scores=dict(sorted(f1_scores.items(), key=lambda x:-x[1]))     \n",
    "f1_scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'15_roberta-large_4_sub_42_5': 71.49465624501515,\n",
       " '15_roberta-large_3_sub_42_5': 71.43314139475369,\n",
       " '15_roberta-large_5_sub_42_5': 71.20900015845348,\n",
       " '15_roberta-large_2_sub_42_5': 71.13385574924035,\n",
       " '15_roberta-large_5_sub_42_4': 70.53994316387748,\n",
       " '15_roberta-large_1_sub_42_5': 70.4428754813864,\n",
       " '15_roberta-large_5_sub_42_3': 70.29998429401601,\n",
       " '15_roberta-large_5_sub_42_2': 69.65732087227414,\n",
       " '15_roberta-large_5_sub_42_1': 69.07854050711194}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_name = './ensemble'\n",
    "file_list = os.listdir(folder_name)\n",
    "count_file = len(file_list)\n",
    "if os.path.isdir('./ensemble_result')==False:\n",
    "    os.mkdir('./ensemble_result')\n",
    "\n",
    "correct = pd.read_csv('../data/dataset/test/dev_final.csv')\n",
    "\n",
    "f1_scores={}\n",
    "file_name1= 'train_15_roberta-large.csv'\n",
    "file_name2 = 'train_sub_42.csv'\n",
    "\n",
    "for weight1 in range(1,6):\n",
    "\n",
    "    print(weight1)\n",
    "\n",
    "    file_name = f'{file_name1[6:-4]}_{weight1}_{file_name2[6:-4]}_5'\n",
    "    ens_result = ensemble(folder_name,file_name1,file_name2,weight1,5)\n",
    "    ens_result.to_csv(f'./ensemble_result/{file_name}.csv')\n",
    "    ens_result= pd.concat([ens_result,correct],axis=1)\n",
    "    f1_scores[file_name]=klue_re_micro_f1(ens_result.pred_label,ens_result.label)\n",
    "\n",
    "for weight2 in range(1,6):\n",
    "\n",
    "    print(weight2)\n",
    "\n",
    "    file_name = f'{file_name1[6:-4]}_5_{file_name2[6:-4]}_{weight2}'\n",
    "    ens_result = ensemble(folder_name,file_name1,file_name2,5,weight2)\n",
    "    ens_result.to_csv(f'./ensemble_result/train_{file_name}.csv')\n",
    "    ens_result= pd.concat([ens_result,correct],axis=1)\n",
    "    f1_scores[file_name]=klue_re_micro_f1(ens_result.pred_label,ens_result.label)\n",
    "\n",
    "f1_scores=dict(sorted(f1_scores.items(), key=lambda x:-x[1]))\n",
    "f1_scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scores=dict(sorted(f1_scores.items(), key=lambda x:-x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'14_5_14_roberta-large_5': 70.74960127591706,\n",
       " '14_4_14_roberta-large_5': 70.69186418962204,\n",
       " '14_3_14_roberta-large_5': 70.46947604550552,\n",
       " '14_5_14_roberta-large_4': 70.40686586141132,\n",
       " '14_2_14_roberta-large_5': 70.0095816033216,\n",
       " '14_1_14_roberta-large_5': 69.69407265774379,\n",
       " '14_5_14_roberta-large_3': 69.48000632211159,\n",
       " '14_5_14_roberta-large_2': 68.75491893593578,\n",
       " '14_5_14_roberta-large_1': 68.1023720349563}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 train_15_roberta-large_3.8_sub_42_5.csv\n",
      "1 train_15_roberta-large_3.8_sub_42_5.csv\n",
      "2 train_15_roberta-large_3.8_sub_42_5.csv\n",
      "3 train_15_roberta-large_3.8_sub_42_5.csv\n",
      "4 train_15_roberta-large_3.8_sub_42_5.csv\n",
      "5 train_15_roberta-large_3.8_sub_42_5.csv\n",
      "6 train_15_roberta-large_3.8_sub_42_5.csv\n",
      "7 train_15_roberta-large_3.8_sub_42_5.csv\n",
      "8 train_15_roberta-large_3.8_sub_42_5.csv\n",
      "9 train_15_roberta-large_3.8_sub_42_5.csv\n",
      "10 train_15_roberta-large_3.8_sub_42_5.csv\n",
      "11 train_15_roberta-large_3.8_sub_42_5.csv\n",
      "12 train_15_roberta-large_3.8_sub_42_5.csv\n",
      "13 train_15_roberta-large_3.8_sub_42_5.csv\n",
      "14 train_15_roberta-large_3.8_sub_42_5.csv\n",
      "15 train_15_roberta-large_3.8_sub_42_5.csv\n",
      "16 train_15_roberta-large_3.8_sub_42_5.csv\n",
      "17 train_15_roberta-large_3.8_sub_42_5.csv\n",
      "18 train_15_roberta-large_3.8_sub_42_5.csv\n",
      "19 train_15_roberta-large_3.8_sub_42_5.csv\n",
      "20 train_15_roberta-large_3.8_sub_42_5.csv\n",
      "21 train_15_roberta-large_3.8_sub_42_5.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'15_roberta-large_3.8_sub_42_5_15_roberta-large_3.8_sub_42_5': 71.50374740870674,\n",
       " 'sub_41_15_roberta-large_3.8_sub_42_5': 71.50374740870674,\n",
       " '15_roberta-large_sub_42_15_roberta-large_3.8_sub_42_5': 71.2150127226463,\n",
       " 'sub_24_15_roberta-large_3.8_sub_42_5': 70.89624156761965,\n",
       " 'sub_29_15_roberta-large_3.8_sub_42_5': 70.83935162895203,\n",
       " 'sub_42_15_roberta-large_3.8_sub_42_5': 70.73366511478567,\n",
       " '14_15_roberta-large_3.8_sub_42_5': 70.72086376627502,\n",
       " 'sub_31_15_roberta-large_3.8_sub_42_5': 70.622009569378,\n",
       " 'sub_20_15_roberta-large_3.8_sub_42_5': 70.49567269866246,\n",
       " '13_15_roberta-large_3.8_sub_42_5': 70.44558957259775,\n",
       " 'sub_35_15_roberta-large_3.8_sub_42_5': 70.39177906229929,\n",
       " '15_roberta-large_15_roberta-large_3.8_sub_42_5': 69.66677047648709,\n",
       " '15_split_2_15_roberta-large_3.8_sub_42_5': 69.64827167980594,\n",
       " 'roberta_large_checkpoint-8000_15_roberta-large_3.8_sub_42_5': 69.52681388012618,\n",
       " '14_snu_15_roberta-large_3.8_sub_42_5': 69.30815663210029,\n",
       " 'sub_8_15_roberta-large_3.8_sub_42_5': 69.2026102180487,\n",
       " 'sub_26_15_roberta-large_3.8_sub_42_5': 68.95787139689578,\n",
       " 'sub_40_15_roberta-large_3.8_sub_42_5': 68.90729531697993,\n",
       " 'sub_6_15_roberta-large_3.8_sub_42_5': 68.73915101783179,\n",
       " 'sub_34_15_roberta-large_3.8_sub_42_5': 68.54146806482363,\n",
       " 'sub_32_15_roberta-large_3.8_sub_42_5': 68.54146806482363,\n",
       " 'sub_1_15_roberta-large_3.8_sub_42_5': 64.3657002607762}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if os.path.isdir('./ensemble_result')==False:\n",
    "    os.mkdir('./ensemble_result')\n",
    "folder_name = './ensemble'\n",
    "file_list = os.listdir(folder_name)\n",
    "count_file = len(file_list)\n",
    "\n",
    "correct = pd.read_csv('../data/dataset/test/dev_final.csv')\n",
    "\n",
    "f1_scores={}\n",
    "file_2 = 'train_15_roberta-large_3.8_sub_42_5.csv'\n",
    "\n",
    "for file_1 in range(count_file):\n",
    "    print(file_1 , file_2)\n",
    "    file_name = f'{file_list[file_1][6:-4]}_{file_2[6:-4]}'\n",
    "    ens_result = ensemble(folder_name,file_list[file_1],file_2)\n",
    "    ens_result.to_csv(f'./ensemble_result/train_{file_name}.csv')\n",
    "    ens_result= pd.concat([ens_result,correct],axis=1)\n",
    "    f1_scores[file_name]=klue_re_micro_f1(ens_result.pred_label,ens_result.label)\n",
    "\n",
    "f1_scores=dict(sorted(f1_scores.items(), key=lambda x:-x[1]))     \n",
    "f1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.2\n",
      "3.4\n",
      "3.6\n",
      "3.8\n",
      "4.0\n",
      "4.2\n",
      "4.4\n",
      "4.6\n",
      "4.8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'15_roberta-large_3.8_sub_42_5': 71.50374740870674,\n",
       " '15_roberta-large_4.0_sub_42_5': 71.49465624501515,\n",
       " '15_roberta-large_3.2_sub_42_5': 71.488,\n",
       " '15_roberta-large_3.4_sub_42_5': 71.46282973621103,\n",
       " '15_roberta-large_3.6_sub_42_5': 71.44911327688129,\n",
       " '15_roberta-large_4.2_sub_42_5': 71.30573248407643,\n",
       " '15_roberta-large_4.8_sub_42_5': 71.19074044712225,\n",
       " '15_roberta-large_4.4_sub_42_5': 71.18105229693211,\n",
       " '15_roberta-large_4.6_sub_42_5': 71.163307411522}"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_name = './ensemble'\n",
    "file_list = os.listdir(folder_name)\n",
    "count_file = len(file_list)\n",
    "if os.path.isdir('./ensemble_result')==False:\n",
    "    os.mkdir('./ensemble_result')\n",
    "\n",
    "correct = pd.read_csv('../data/dataset/test/dev_final.csv')\n",
    "\n",
    "f1_scores={}\n",
    "file_name1= 'train_15_roberta-large.csv'\n",
    "file_name2 = 'train_sub_42.csv'\n",
    "\n",
    "for weight in range(1,10):\n",
    "    weight1 = 3+ weight*0.2\n",
    "    print(weight1)\n",
    "\n",
    "    file_name = f'{file_name1[6:-4]}_{weight1}_{file_name2[6:-4]}_5'\n",
    "    ens_result = ensemble(folder_name,file_name1,file_name2,weight1,5)\n",
    "    ens_result.to_csv(f'./ensemble_result/{file_name}.csv')\n",
    "    ens_result= pd.concat([ens_result,correct],axis=1)\n",
    "    f1_scores[file_name]=klue_re_micro_f1(ens_result.pred_label,ens_result.label)\n",
    "\n",
    "# for weight2 in range(1,6):\n",
    "\n",
    "#     print(weight2)\n",
    "\n",
    "#     file_name = f'{file_name1[6:-4]}_5_{file_name2[6:-4]}_{weight2}'\n",
    "#     ens_result = ensemble(folder_name,file_name1,file_name2,5,weight2)\n",
    "#     ens_result.to_csv(f'./ensemble_result/train_{file_name}.csv')\n",
    "#     ens_result= pd.concat([ens_result,correct],axis=1)\n",
    "#     f1_scores[file_name]=klue_re_micro_f1(ens_result.pred_label,ens_result.label)\n",
    "\n",
    "f1_scores=dict(sorted(f1_scores.items(), key=lambda x:-x[1]))\n",
    "f1_scores\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
